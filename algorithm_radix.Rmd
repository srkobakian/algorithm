---
title: "An algorithm for a spatial mapping using a hexagon tilegram, with application to Australia disease maps"
author:
  - name: Stephanie Kobakian
    url: https://github.com/srkobakian
    affiliation: Queensland University of Technology
date: "`r Sys.Date()`"
output: radix::radix_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = FALSE)
```

# Abstract

<!--
problem has been studied
what is the goal of the thesis/paper
brief statement on existing solutions and their drawbacks
major  contributions  of  the  thesis
State  briefly  assumptions  and  limitations. 
The  abstract  should  also  include  major idea(s)
the type (e.g. performance, complexity) and result of analysis done
-->

KEYWORDS: 

# Introduction

Spatial distrbutions have utilised alternative representations of geography for many years. In modern times with the ease of interactivity and animation, alternative representations have been popularised by online news sites, with a focus on public consumption. Applications are increasingly widespread, especially in the area of disease mapping, election results and .


## Motivation
<!--
Problem   statement   (precise   definition   and   importance);   
avoid   very   technical definitions  and  statements, give  good  intuition for your involved definitions or facts. 
-->

Spatial distributions of people and human related statistics are not well presented in geographic maps. Populations congregate around major cities and the lack of land available encourages vertical living. Government bodies define localities, attempting to evenly distribute the population into measureable areas. As the rural areas of Australia are often sparsely populated in comparison to their urban centres the square meterage of the geographic areas may vastly differ in size.

Alternative mapping methods allow increased understanding of the spatial distribution of a variable amongst the population. Allowing the focus to be placed on the distribution of the statistics between the groups of areas, not the geography.

<!--
Existing  solutions  and  their  criticism  (limit  only  to  those  directly  relevant  to  the  contribution of the thesis; give a motivation for doing research on the topic); 
-->

Extremely small geographic areas are lost on large geographic maps, areas in Sydney or Melbourne are not easily compared at a high level.
Cartograms allow an alternative view. Placingimportance on the statistic of interest, allowing unequal map space on the display to represent differences in the statistic. These maps rely on the statistic of interest to determine the layout, and often fail to preserve a recognisable view of Australia.
Tile grams allow a better preservation of relationships. Decrease the emphasis on the amount of geograhic area considered to be interesting. Focus on the relationship between neighbours, in considering aggregated statistics of heterogeneous regions.

<!--
With different characteristics or properties:

-->

Australia and Canada present an application that contains an unusual population settlement and dispersion over the geographical space: 
- Australia: Dense south east, sparse central and west




## Background
<!--
basic facts needed to tune the reader to the thesis or paper
-->

- Choropleth methods are accurate geographically.
- Cartogram alternative map has been used historically.
- Spatial relationships are preserved.

<!--
all  known  results  relevant  to  the  problem  stated,  
whether  or  not  they  are  used  in  proposed  contributions
-->

<!--
Discuss  advantages  and  drawbacks  of  known  solutions  that  are  relevant  to  your  problem, 
discuss  the  relevance of each reviewed item to your topic and your solutions. 
-->

<!--
For  every  discussed  reference,  it  is  very  important  to  relate  them  to  your  problem  and  contribution  in  one  of  several  ways:  
it  does  not  exactly  solve  the  same  problem,
it  solves  the  same  problem  but  makes  different  assumptions  about  the  system, 
it  has  some  limitations  that you  do  not  have, 
it  makes  the  same  assumptions  but  does  not  work  well  under  certain  
conditions  and  scenarios  for  which  you  have  better  solutions,  or, 
if  none  of  these  is  true,  you are   considering   it   as   valid   competitor,   and   will   try   to   defeat   it   in   your   analytical   or 

experimental  comparisons.  
-->
## Proposed Solution

<!--
Contributions (proposed solutions; why they are expected to be better; essence of the idea(s) used in proposed solutions); 
What the algorithm is trying to do:
-->

- Like Dorling, same shape will be used.
Like tilegram, tessellation using equally sized shapes.

- Allocate each geographic area to a map space of consistent tessellated shape

which is different from existing algorithms:
- contiguous, keeps exact neighbours, no recognisable shape
- non contiguous, keeps shape, can lose neighbours


<!--
Why the reader should believe that it is correct or reasonable.
-->
- Clear to see spatial distribution, 
_ Should keep neighbours relationships intact as geographic neighbours will have similar values

<!--
If it is supposed to be “better”, what is meant by better.
-->
Easier to read distribution at a distance, see a much larger area, general relationship at a glance

<!--
Conditions, assumptions and limitations of the research done; 
-->
Works well for America, states are almost homogeneous 
Works well for England, London is the biggest issue, pushing out rural areas does not disturb population dense areas.

<!--
Analysis  (theoretical,  experimental,  simulations,  implementations, done  in  thesis;  under what conditions and scenarios is your solution best?  
-->

Our solution considers multiple population dense areas.

Allows dispersion to be increased when needed, and distance from origin to be considered


The Dorling maps in [@TVSSS] give examples of displacing central geographically small, population dense areas.
This inspired the concept of this algorithm. 



# Algorithm

The algorithm operates on a set of polygons.
There are parameters used in the process that may be provided, or will be automatically derived.
All necessary functions are exported, with a main function `create_hexmap` used to step through automatically.

## Parameters

As the `create_hexmap` function requires several parameters, if they are not provided, the information will be derived from the polygon set used. 

**The following must be provided to `create_hexmap`:**
```{r table_necessary}
knitr::kable(tibble::tibble(parameter = c('shp', 
  'shp_path',
  'sf_id',
  'focal_points'),
  description = c('an Rdata object containing the polygon information', 'character string location of the shape file that contains the polygon information', 'name of a unique column that distinguishes areas',
    'a data frame of reference locations when allocating hexagons, capital cities of Australia are provided as capital_cities'
    )))

```

```{r libraries}
library(tidyverse)
# To install sugaRbag:
# devtools::install_github("srkobakian/sugaRbag")
library(sugaRbag)
```

The polygon set of Local Government Areas in Australia in 2011 is stored in the sugaRbag package data as `tas_sa2`. To create this object:

```
# Download resource 
# link to folder containing .shp file on sugaRbag site.

aus_sa2 <- read_shape("file location")

filter for Tasmanian areas

tas_sa2 <- filter(aus_sa2, aus_sa2$STE_NAME11 == "Tasmania)
```

A column of the data set must be used as a unique identifier of areas.

```{r data}
sf_id <- "SA2_5DIG16"
focal_points <- sugaRbag::capital_cities
```


**The following will be determined within `create_hexmap` if not provided. They are created throughout the following example:**

```{r}
knitr::kable(tibble(parameter = c('projstring', 
  'epsg', 'buffer_dist', 'hex_size',  'filter_dist', 'width'),
  description = c('a string to indicate the projection and epsg', 'the four character string to indicate the CRS', 
    'a float value for distance in degrees to extend beyond the - geometry provided',
    'a float value in degrees for the diameter of the hexagons', 'amount of hexagons around centroid to consider for allocation',
    'the angle used to filter the grid points around a centroid')))
```



When utilising individual `sugaRbag` functions, we recommend the following approach:

## Polygon Information

Begin with a set of polygons.
There are several ways of providing the set of polygons.
The following methods are available via the `read_shape` function. It utilises the `st_read` function is to create the sf object.

- If the shape file is an .Rda file, it is loaded into the current environment.
- To utilise a custom shape file from a directory on your device, provide the file path for .shp file.

<!--
```
# Read in shape information
shp <- read_shape(shp_path = shp_path)
```
-->

Empty geometries are removed from the sf object, and the remaining polygons are projected to the Australian standard using `projstring`.

We will use the Statical Areas (Level 2) of Australia, provided by Australian Bureau of Statistics. With only those from Tasmania as an example:

```{r}
# Convert to a simple features object
tas_sa2 <- sf::st_as_sf(tas_sa2)

# Select only desired LGA areas, those from tas.
tas_sa2[[sf_id]] <- droplevels(as.factor(tas_sa2[[sf_id]]))

fort_tas <- fortify_sfc(tas_sa2)
```

```{r}
# Include area variable
area_var <- fort_tas %>% 
  distinct(SA2_5DIG16, .keep_all = TRUE) %>% 
  select(SA2_5DIG16, AREASQKM16)
```


```{r centroids}
## Use the create_centroids function to find polygon centroids:
centroids <- create_centroids(shp_sf = tas_sa2, sf_id = sf_id) %>%
  left_join(., select(area_var, SA2_5DIG16, AREASQKM16), by = "SA2_5DIG16")
```


```{r, fig.cap="tas Local Government Areas and derived centroids."}
end_cents <- ggplot() + 
  geom_polygon(aes(x = long, y = lat, group = group), data = fort_tas, fill = "grey", colour = "white") + geom_point(aes(x=longitude, y = latitude, colour = log(AREASQKM16)), data= centroids) + theme_void() + coord_equal()
end_cents

#ggplot() + geom_histogram(aes(x = log(AREASQKM16), fill = log(AREASQKM16)), data= centroids, bins = 20) 
```


## Hexagon grid

Create a grid of hexagon centroids using the `create_grid` function.

The grid creation takes several steps. It requires the centroids, the bounding box, the hexagon size and the buffer distance.

```{r bbox}
## Not necessary when using `create_hexmap`:
## create the bounding box from the set of polygon centroids:
bbox <- tibble::tibble(min = c(min(centroids$longitude), min(centroids$latitude)),
        max = c(max(centroids$longitude), max(centroids$latitude)))

hex_size <- (bbox$max[1] - bbox$min[1])/(bbox$max[2] - bbox$min[2]) / 5
  
buffer_dist <- max((bbox$max[1] - bbox$min[1]), (bbox$max[2] - bbox$min[2]))*0.3
```


### Step 1: Expand the grid
Two sequences are used, one for longitude and another for latitude.
The sequences begin at the minimum longitude or latitude, minus the buffer distance.
Equally spaced intervals, the size of the hexagons, are created up to the maximum longitude or latitude, plus the buffer distance.

An individual point is created from all combinations of longitude and latitude sequences.

```{r grid}
grid <- tibble::as_tibble(expand.grid(hex_long = seq(bbox$min[1] - buffer_dist,
    bbox$max[1] + buffer_dist,
    hex_size),
    hex_lat = seq(bbox$min[2] - buffer_dist,
        bbox$max[2] + buffer_dist,
        hex_size)))
```

```{r plot_grid}
ggplot() + geom_polygon(aes(x = long, y = lat, group = group), data = fort_tas, fill = "grey", colour = "white") + geom_point(aes(x=longitude, y = latitude), data= centroids, colour = "#b2df8a") + theme_void() + coord_equal() +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#1f78b4", data = grid, size = 0.75) 
```

This grid is square, which will not facilitate tessellated hexagons. 
Every second latitude (row) of points will be shifted right by half of the hexagon size.

```{r shift}
# Find every second latitude
shift_lat <- grid %>% dplyr::select(hex_lat) %>%
    dplyr::distinct() %>%
    dplyr::filter(dplyr::row_number() %% 2 == 1) %>% unlist()

# Shift the longitude of every second latitude to the right to make hex structure
grid <- grid %>%
    dplyr::mutate(hex_long = ifelse(hex_lat %in% shift_lat, hex_long,
        hex_long + (hex_size / 2))) %>%
    dplyr::mutate(id=1:NROW(.)) %>%
    dplyr::mutate(assigned=FALSE)
```

```{r plot_shift}
ggplot() + geom_polygon(aes(x = long, y = lat, group = group), data = fort_tas, fill = "grey", colour = "white") + geom_point(aes(x=longitude, y = latitude),data= centroids, fill = "#b2df8a") + theme_void() + coord_equal() +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#1f78b4", data = grid, size = 0.75) 
```

Each row and column is given an ID

```{r grid_id}
grid <- grid %>%
    mutate(hex_long_int = dense_rank(hex_long)-1,
        hex_lat_int = dense_rank(hex_lat)-1)
```

There are more points than necessary on this grid.

### Step 2: Rolling windows

To filter the grid for appropriate hexagons for allocation,
the `create_buffer` function is called from `create_grid`.

It finds the amount of columns and rows needed to capture the set of centroids.

```{r}
nlong <- length(unique(grid$hex_long))
nlat <- length(unique(grid$hex_lat))

centroids <- centroids %>%
  mutate(long_int = round((longitude-min(grid$hex_long))/(max(grid$hex_long)-min(grid$hex_long))*nlong, 0),
          lat_int = round((latitude-min(grid$hex_lat))/(max(grid$hex_lat)-min(grid$hex_lat))*nlat, 0))
```

The rows and columns are divided into 20 groups. The amount of rows in each latitude group and the amount of columns in each longitude group are then used as the width of manual rolling windows.

```{r echo = FALSE}
# Amount of lats and longs in each group
lat_size = round(nlat/20,0)
long_size = round(nlong/20,0)
```

The first rolling window function finds the minimum and maximum centroid values for the groups of longitude columns and the groups of latitude rows.
The specific rows and columns in the rolling windows are defined.

```{r echo = FALSE}
 # make a list of groups, manual sliding windows
    nlat_list <- purrr::map2(seq(1:nlat), lat_size + seq(1:nlat), c)
    nlong_list <- purrr::map2(seq(1:nlong), long_size + seq(1:nlong), c)


    lat_window <- function(x, cents = centroids, maximum = nlat){
        max_int = min(x[2],maximum)

        cents_in <- filter(cents, between(lat_int, x[1], max_int))
        return(cents_in)
    }

    long_window <- function(x, cents = centroids, maximum = nlong){
        max_int = x[2]
        while (max_int > maximum){
            max_int = max_int - 1
        }

        cents_in <- filter(cents, between(long_int, x[1], max_int))
        return(cents_in)
    }
    

    # LATITUDE ROWS FILTER
    # amount of latitude in sliding window
    lat_windows <- purrr::map(.x = nlat_list, .f = lat_window)

    # find the min and max longitude for each latitude
    range_rows <- purrr::map_dfr(.x = lat_windows,
        .f = function(x) {x %>%
                dplyr::summarise(
                    long_min = ifelse(purrr::is_empty(long_int), NA, min(x$long_int)),
                    long_max = ifelse(purrr::is_empty(long_int), NA, max(x$long_int))
                )}
    )
```



The second rolling window function finds the average of the rolling minimum and rolling maximum centroid values, for the longitude columns and latitude rows.

```{r echo = FALSE}
 # smooth the minimums
    av_range_rows <- purrr::map_dfr(.x = nlat_list, .f = function(x, rows = range_rows) {
        rows[x[1]:min(x[2], NROW(rows)),] %>%
            dplyr::summarise(mean_long_min = mean(long_min, na.rm=T), mean_long_max = mean(long_max, na.rm=T))
    }) %>%
        bind_cols(lat_id = c(seq(1:nlat) +lat_size), .)

    # LONGITUDE COLS FILTER
    long_windows <- purrr::map(.x = nlong_list, .f = long_window, centroids, nlong)

    # find the min and max longitude for each latitude
    range_cols <- purrr::map_dfr(.x = long_windows, .f = function(x) { x %>%
            dplyr::summarise(
                lat_min = ifelse(purrr::is_empty(lat_int), NA, min(x$lat_int)),
                lat_max = ifelse(purrr::is_empty(lat_int), NA, max(x$lat_int))
            )}
    )

    # smooth the minimums
    av_range_cols <- purrr::map_dfr(.x = nlong_list, .f = function(x, cols = range_cols) {
        cols[x[1]:min(x[2], NROW(cols)),] %>%
            dplyr::summarise(mean_lat_min = mean(lat_min, na.rm=T), mean_lat_max = mean(lat_max, na.rm=T))
    }) %>%
        bind_cols(long_id = c(seq(1:nlong) + round(long_size/2)), .)

```

<!--
Figure of rolling window construction
-->

### Step 3: Filtering the grid

Only the grid points between the rolling average of the minimum and maximum centroid values are kept, for each row and column of the grid.

```{r echo = FALSE}
    # APPLY A BUFFER
    # change buffer to amount of hexagons (ints) either side
    hex_buffer <- floor(buffer_dist/hex_size)

    grid <- grid %>%
        left_join(., av_range_rows, by = c("hex_lat_int" = "lat_id")) %>%
        left_join(., av_range_cols, by = c("hex_long_int" = "long_id")) %>%
        rowwise() %>%
        mutate(long_buffer = ifelse(between(hex_long_int,mean_long_min - hex_buffer,
            mean_long_max + hex_buffer), "in", "out")) %>%
        mutate(lat_buffer = ifelse(between(hex_lat_int,mean_lat_min - hex_buffer,
            mean_lat_max + hex_buffer), "in", "out")) %>%
        filter(lat_buffer =="in" | long_buffer == "in")

```


```{r plot_buffer}
ggplot() + geom_polygon(aes(x = long, y = lat, group = group), data = fort_tas, fill = "grey", colour = "white") + geom_point(aes(x=longitude, y = latitude),data= centroids, fill = "#b2df8a", fill = "red") + theme_void() + coord_equal() +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#a6cee3", data = full_grid, size = 0.25) +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#1f78b4", data = grid, size = 0.75)
```


## Centroid to focal point distance 

```{r split_centroids}
# Split the centroid data set
centroids <- centroids %>% 
  nest(longitude, latitude) %>% 
  mutate(closest = map(data, closest_focal_point, focal_points = focal_points)) %>% 
  unnest(data, closest) %>% 
  arrange(focal_distance)
```

For each polygon centroid in the set. Find the distance to each of the focal points provided. The closest focal point name, the distance to the polygon centroid, and the angle from focal point to polygon centroid will be returned and added to the polygon data set in the polygon centroid row. 

The distance between the polygon centroid and it's closest focal point data set is used to arrange the data set for allocation. The points are arranged in ascending order, from the centroid closest to any of the focal points, to the furthest.

## Allocation of centroids

Define a distance around a centroid to consider for possible hexagon location.

```{r f_dist}
## Not necessary when using `create_hexmap`:
## Consider hexagon points up to a certain distance from centroid

filter_dist <- (hex_size)*10
```

Allocate each centroid, beginning with the closest to a focal point, extending to the furthest. Will preserve spatial relationship.

```{r}
width = 15
```


```{r, eval = FALSE}
hexmap_allocation <- allocate(centroids = centroids,
        hex_grid = grid,
        hex_size = hex_size,
        filter_dist = filter_dist,
        width = width,
        focal_points = focal_points,
        verbose = TRUE,
        id = sf_id)
```


Allocation of all centroids can now take place using the set of polygon centroids and the hexagon map grid. 
For each polygon centroid, only the hexagon grid points that have not yet been used can be considered.

```{r arrange}
s_centroids <- centroids %>% arrange(focal_distance)

s_centroids <- split(s_centroids, s_centroids[["focal_distance"]])
        
# Set up allocation data frame
centroid_allocation <- NULL
```

The filter distance parameter is used to subset possible grid points to only those surrounding the polygon centroid within the filter distance.

```{r orig_dist}
# keep value to reset expanded distances
expand_dist <- filter_dist
```


The following example considers one of the Local Government Areas. 
These steps are repeated for each polygon.

### Step 1: Filter the grid for unassigned hexagon points

Keep only the available hexagon points, this will prevent multiple areas being allocated to the same hexagon.

```{r available_points}
# filter for only the available hex grid points
hex_grid <- grid %>% filter(!assigned)
```

### Step 2: Filter the grid points for those closest to the centroid

This will allow only the closest points, that are not assigned, to be considered.

```{r close_points}
# filter grid for avaiable points
centroid1 <- centroids %>% head(1)

flong <- centroid1$longitude
flat <- centroid1$latitude

hex_grid <- hex_grid %>% ungroup() %>%
        filter(flat - filter_dist < hex_lat & hex_lat < flat + filter_dist) %>%
        filter(flong - filter_dist < hex_long & hex_long < flong + filter_dist)

```

Create a box filter

```{r, echo = FALSE}
ggplot() + geom_polygon(aes(x = long, y = lat, group = group), data = fort_tas, fill = "grey", colour = "white") + geom_point(aes(x=longitude, y = latitude),data= centroid1, fill = "red") + theme_void() + coord_equal() +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#a6cee3", data = grid, size = 0.25) +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#1f78b4", data = hex_grid, size = 0.75)

```


Create circle filter

```{r}
    hex_grid <- hex_grid %>%
        rowwise %>%
        mutate(
        hex_lat_c = hex_lat - flat,
        hex_long_c = hex_long - flong) %>%
        mutate(hyp = ((hex_lat_c^2) + (hex_long_c^2))^(1/2))


        f_angle <- centroid1 %>%
            mutate(atan = atan2(latitude-latitude1,longitude-longitude1),
                angle = (atan*180/pi),
                pangle = ifelse(angle<0, angle +360, angle)) %>% pull()


        hex_grid <- hex_grid %>%
            # create circle of radius: filter_dist
            filter(hyp < filter_dist) %>%
            mutate(
                # geosphere takes a long time
                angle = f_angle,
                angle_plus = (angle + width)%%360,
                angle_minus = (angle - width)%%360,
                atan = atan2(hex_lat_c, hex_long_c),
                hex_angle = (atan*180/pi),
                hex_angle = ifelse(hex_angle<0, hex_angle +360, hex_angle))

```


```{r, echo = FALSE}
ggplot() + geom_polygon(aes(x = long, y = lat, group = group), data = fort_tas, fill = "grey", colour = "white") + geom_point(aes(x=longitude, y = latitude),data= centroid1, fill = "red") + theme_void() + coord_equal() +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#a6cee3", data = grid, size = 0.25) +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#1f78b4", data = hex_grid, size = 0.75)
```


Filter for angle within circle, relates hexagon location to focal point, Sydney.

```{r}
# Filter for angle within circle

        if (hex_grid$angle_minus[1] < hex_grid$angle_plus[1]) {
            hex_grid <- hex_grid %>%
                # create slice of 60 degrees from centroid
                filter(angle_minus < hex_angle & hex_angle < angle_plus)
        } else {
            hex_grid <- hex_grid %>%
                # create slice of 60 degrees from centroid
                filter(hex_angle < angle_plus | angle_minus > hex_angle)
        }

```





```{r}

ggplot() + geom_polygon(aes(x = long, y = lat, group = group), data = fort_tas, fill = "grey", colour = "white") + geom_point(aes(x=longitude, y = latitude),data= centroid1, fill = "red") + theme_void() + coord_equal() +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#a6cee3", data = grid, size = 0.25) +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#1f78b4", data = hex_grid, size = 0.75)

```



```{r}

# Choose first available point
        cent <- centroid1 %>% dplyr::rename(focal_point = points, focal_dist = focal_distance, focal_angle = angle)

        # Filter should give one hex point
        hex <- hex_grid %>% 
          ungroup %>% 
          filter(hyp == min(hyp)) %>%
          select(hex_long, hex_lat, hex_id = id)

        #update grid to show this centroid as assigned
        hex_grid[which(hex_grid$id == hex$hex_id),]$assigned <- TRUE

        centroid_allocation <- bind_rows(centroid_allocation, dplyr::bind_cols(cent, hex)) %>% as_tibble()

```


Using the angle between each polygon centroid, and it's the closest focal point, the subset of points is filtered again.
Of these possible points, only those within a specific amount of degrees plus and minus a specific angle range are kept. This angle begins at 30 degrees by default, and may increase if necessary.

If no available hexagon grid point is found within the original filter distance and angle, the distance is expanded, only when a maximum distance is reached will the angle expand to accommodate more possible grid points.  

The allocation is returned and combined with the data relating to each polygon.

```{r}
hex_points_df <- centroid_allocation %>% 
  group_by(SA2_CODE11) %>%
  nest() %>%
  mutate(hex_points = 
      map(.x = data,.f = function(a) { 
        fortify_hexagon(data = a, hex_size = hex_size)})) %>%
  unnest(data) %>%
  unnest(hex_points)
```

```{r}
ggplot(hex_points_df) + 
  geom_polygon(aes(x = hexv_long, y = hexv_lat, group = SA2_CODE11)) +
  coord_equal() +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#a6cee3", data = grid, size = 0.25) +
  geom_point(aes(x = hex_long, y = hex_lat), colour = "#1f78b4", data = hex_grid, size = 0.75)
```


```{r fullhexmap}
lga_map <- create_hexmap(shp = tas_sa2, sf_id = "SA2_CODE11", buffer_dist = NULL, filter_dist = 10, export_shp = FALSE, focal_points = sugaRbag::capital_cities, projstring = projstring, verbose = TRUE)

hexmap_lga <- left_join(tas_sa2, 
  lga_map)

```


```{r}
end_hex <- ggplot() + 
  geom_polygon(aes(x = long, y = lat, group = group), data = fort_tas, fill = "grey", colour = "white") +
  theme_void() + coord_equal() +
    geom_hex(aes(x = hex_long, y = hex_lat, fill = AREA_SQKM), data = hexmap_lga, 
      position = "identity", stat = "identity")

gridExtra::grid.arrange(end_hex, end_cents)
```



## Applications of algorithm

<!--
Is  your  solution  always  working?  
Can  you  prove it? 
How does it work? 
-->

Examples of Melbourne, tas, Australia
At different levels, distance from original centroids, change in area

LGA of all Australia
SA2 for tas

<!--
Is your analysis about worst case or average case? 
What kind of theoretical and analytical support can you give for your proposed scheme/solution? 
-->


# Evaluation

<!--
The  performance  of  your  solution  can  be  compared  with  existing  solutions,  if  any  exists 
under  same  or  similar  assumptions,  analytically  and/or  by  doing  a  simulation.

Find examples of measures of cartogram effectiveness


-->

Measure changes to areas:
Each hexagon area in the set of $npolys$ is standardised to 1 unit.
Where 1 unit is the area of a hexagon of the designated size.

$area_{h_i} = 1$

$area_h = 1 * npolys$

$y_i$ denotes the statistic of interest for polygon i, where i = 1,...,npolygs
$x_i$ denotes the spatial area for polygon i, where i = 1,...,npolys

Areal Statistic Distortion is the change in the areal distribution of the set of polygons.
Difference between space taken by polygons and space taken by hexagons, with respect to the desired statistic. Setting the desired statistic to area gives the change in map space used to represent the polygons. 

The average when considering area used to display:

$A = \sum_{i=1}^{npolys}y_ix_i/ \sum_{i=1}^{npolys}x_i$

$H = \sum_{i=1}^{npolys}y_i/npolys$

Using $w_i = x_i/\sum_{i=1}^{npolys}x_i$

$\sqrt{ 1/npolys\sum_{i=1}^{npolys}(y_i - \bar y)^2 w_i }$

Considering only a local area distortion: 
Where the subset used contains only neighbours within a certain distance of the polygon centroid

Where $\bar y_d$ is the average of the polygon statistics considering only the polygons where the distance between polygon centroid x_i and polygon centroid x_p is less than d:

$d(x_ix_p) < d$


$\sqrt{ 1/npolys\sum_{i=1}^{npolys}(y_i - \bar y_d)^2 w_i }$

Old neighbours over new neighbours?
<!--
Apply methods of evaluation used elsewhere
Nusrat, Alam and Kobourov:
- Statistical accuracy: how well do the modified areas
represent the corresponding statistic shown (e.g.,
population or GDP). This is measured in terms of
“cartographic error.”
- Geographical accuracy: how much do the modified
shapes resemble the original geographic shapes and
how well preserved are their relative positions.
- Topological accuracy: how well does the topology (as
measured by adjacent regions) of the cartogram
match that of the original map.
-->

# Summary

<!--
What did you achieve with this research? 
What are the drawbacks of your solution(s)? 
What kind  of  future  work  can  be  done? 
Do  you  have  some  ideas  that  you  intend  to  study  further? 
The  ownership  of  some  other  possible  solutions,  not  fully  explored,  or  subject  of  your  
forthcoming  different  article,  can  be  protected  by  outlining  them  briefly  in  the  conclusion  
section, sometimes with reference to upcoming article. 
-->

# Discussion


\pagebreak

# Reference List

<div id="refs"></div>